{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4980b274-aa18-404e-aa81-f7efaf694f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "from faker_music import MusicProvider\n",
    "from faker.providers.date_time import Provider as DatetimeProvider\n",
    "from random import randrange, choice\n",
    "import datetime\n",
    "faker = Faker()\n",
    "conn = psycopg2.connect(\"host=db dbname=postgres user=postgres password=root\")\n",
    "faker.add_provider(MusicProvider)\n",
    "faker.add_provider(DatetimeProvider)\n",
    "    \n",
    "def execute_commands(commands, printflag=None):\n",
    "    if isinstance(commands, str): commands = [commands]\n",
    "    \n",
    "    for command in commands:\n",
    "        try:\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(command)\n",
    "            if printflag: print(cur.fetchall())\n",
    "            cur.close()\n",
    "        except Exception as error:\n",
    "            print(error)\n",
    "            conn.rollback()\n",
    "            cur.close()\n",
    "            cur = None\n",
    "\n",
    "    # close communication with the PostgreSQL database server\n",
    "    # commit the changes\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1ea4859-bd46-4484-8084-878d27c033ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sql_to_dataframe(conn, query, column_names):\n",
    "    \"\"\"Import data from a PostgreSQL database using a SELECT query \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(\"Error: %s\" % error)\n",
    "        cursor.close()\n",
    "        return 1\n",
    "    # The execute returns a list of tuples:\n",
    "    tuples_list = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    # Now we need to transform the list into a pandas DataFrame:\n",
    "    df = pd.DataFrame(tuples_list, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39af27ba-d251-4fe0-8322-20ad85cf7e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop all tables\n",
    "delete_table_commands = [\n",
    "\"DROP SCHEMA public CASCADE;\",\n",
    "\"CREATE SCHEMA public;\"\n",
    "]\n",
    "execute_commands(delete_table_commands)\n",
    "faker.unique.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41c19cb8-3af2-4ac4-b8ac-2fd74f474830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create all tables\n",
    "create_table_commands = [\n",
    "    \"\"\"\n",
    "    CREATE TABLE persons (\n",
    "        person_id SERIAL PRIMARY KEY,\n",
    "        first_name VARCHAR(255) NOT NULL,\n",
    "        last_name VARCHAR(255) NOT NULL\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE albums (\n",
    "      album_id SERIAL PRIMARY KEY\n",
    "      , title VARCHAR(255) NOT NULL\n",
    "      , author VARCHAR(255) NOT NULL \n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE copies(\n",
    "      copy_id SERIAL PRIMARY KEY\n",
    "      , album_id INTEGER NOT NULL REFERENCES albums (album_id)\n",
    "      , person_id INTEGER NOT NULL REFERENCES persons (person_id)\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE loans(\n",
    "      loan_id SERIAL PRIMARY KEY\n",
    "      , copy_id INTEGER NOT NULL REFERENCES copies (copy_id)\n",
    "      , start_date DATE NOT NULL \n",
    "      , end_date DATE NOT NULL\n",
    "      , person_id INTEGER NOT NULL REFERENCES persons (person_id)\n",
    "    )\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "execute_commands(create_table_commands)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d28cbab-edb2-475f-807d-bb337a3522cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate fake persons\n",
    "fake_person_commands = []\n",
    "person_data = [(faker.unique.random_int(), faker.first_name(),faker.last_name() ) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a49769b-b82b-4dbd-a4b9-6d0fddc8bade",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert fake people\n",
    "for data in person_data:\n",
    "    fake_person_commands.append(f\"INSERT INTO persons(person_id, first_name, last_name) VALUES ({data[0]}, '{data[1]}', '{data[2]}')\")\n",
    "    \n",
    "execute_commands(fake_person_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f451e791-cc5e-4061-a192-b5d401a56d58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_id first_name last_name\n",
      "0        238     Joanna  Bautista\n",
      "1       9455        Kim      Lane\n",
      "2       4636      Jesse    George\n",
      "3       6800      Wendy   Johnson\n",
      "4       1712    Rachael     Smith\n",
      "5       2736        Kim  Petersen\n",
      "6        554     Jeremy  Thompson\n",
      "7       2277       Erin    Suarez\n",
      "8       9799     Kelsey   Jackson\n",
      "9       4082     Regina   Roberts\n"
     ]
    }
   ],
   "source": [
    "# Get dataframe from person table\n",
    "column_names = ['person_id','first_name','last_name']\n",
    "query = \"\"\"SELECT * FROM persons;\"\"\"\n",
    "persons_df = sql_to_dataframe(conn, query, column_names)\n",
    "print(persons_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca24a463-e6cc-490c-8547-32560b3285f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate fake albums\n",
    "fake_album_commands = []\n",
    "album_data = [(faker.unique.random_int(), faker.music_subgenre(), faker.first_name()+ \" \" + faker.last_name()) for _ in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ba890846-67ee-49df-833f-a35782052539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Insert fake albums\n",
    "for data in album_data:\n",
    "    fake_album_commands.append(f\"INSERT INTO albums(album_id, title, author) VALUES ({data[0]}, '{data[1]}', '{data[2]}')\")\n",
    "    \n",
    "execute_commands(fake_album_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3db40d6c-81a0-47ce-9e03-43771dd45fb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   album_id                title             author\n",
      "0      2411                March        Jack Knight\n",
      "1      9579               Boogie     Kathryn Martin\n",
      "2      1885     Contemporary R&B        James Woods\n",
      "3       762                March     Madison Cortez\n",
      "4      6366  Contemporary Celtic      April Cabrera\n",
      "5      4852         Parody Music  Matthew Armstrong\n",
      "6      8886          Iranian Pop         Erin Gibbs\n"
     ]
    }
   ],
   "source": [
    "# Get dataframe from album table\n",
    "column_names = ['album_id','title','author']\n",
    "query = \"\"\"SELECT * FROM albums;\"\"\"\n",
    "albums_df = sql_to_dataframe(conn, query, column_names)\n",
    "print(albums_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba8a4f34-446b-471d-ab19-158828f1e33a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate fake copies\n",
    "fake_copy_commands = []\n",
    "copy_data = [(faker.unique.random_int(), albums_df.iloc[randrange(albums_df.shape[0])]['album_id'], persons_df.iloc[randrange(persons_df.shape[0])]['person_id']) for i in range(1,10)]\n",
    "\n",
    "# Insert fake copies\n",
    "for data in copy_data:\n",
    "    fake_copy_commands.append(f\"INSERT INTO copies(copy_id, album_id, person_id) VALUES ({data[0]}, '{data[1]}', '{data[2]}')\")\n",
    "\n",
    "execute_commands(fake_copy_commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "155b3bcc-eee2-433a-a3ec-e079fa64aeb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   copy_id  album_id  person_id\n",
      "0     2773      8886       4636\n",
      "1      913      8886       2736\n",
      "2      612      6366       4636\n",
      "3     1371      2411       4082\n",
      "4     1080      9579       6800\n",
      "5     6915       762       4636\n",
      "6     5871      6366        238\n",
      "7     8248      8886       9455\n",
      "8     5396      2411       6800\n"
     ]
    }
   ],
   "source": [
    "# Get dataframe from copies table\n",
    "column_names = ['copy_id','album_id','person_id']\n",
    "query = \"\"\"SELECT * FROM copies;\"\"\"\n",
    "copies_df = sql_to_dataframe(conn, query, column_names)\n",
    "print(copies_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a81258e3-7a81-43ec-aa1b-f210b7458137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate fake loans\n",
    "loan_data = []\n",
    "# Current loans interval\n",
    "earliest_start_loan_date = datetime.date.fromisoformat('2022-12-04')\n",
    "latest_end_loan_date = datetime.date.fromisoformat('2023-06-01')\n",
    "\n",
    "copy_id_list = copies_df['copy_id'].tolist()\n",
    "person_id_list = persons_df['person_id'].tolist()\n",
    "for copy_id in copy_id_list:  # for all copies\n",
    "    # Generate 0-3 non-overlapping past loans for each copy\n",
    "    num_loans = randrange(0, 3)\n",
    "    first_available_date = datetime.date.today() - datetime.timedelta(days=365)  # start loaning out this copy from a year ago\n",
    "    for _ in range(num_loans):\n",
    "        loan_id = faker.unique.random_int()\n",
    "        start_date = faker.date_between(first_available_date)\n",
    "        end_date = faker.date_between(start_date)\n",
    "        person_id = choice(person_id_list)\n",
    "        loan_data.append((loan_id, copy_id, start_date, end_date,person_id))\n",
    "\n",
    "        first_available_date = end_date  # update first_available_date to avoid overlapping loans for the same copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5ea300a2-cb51-43fb-8506-3949ff01d7a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(4427) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(1243) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(63) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(2049) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(2950) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(8615) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(6549) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(4397) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(692) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(8112) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(7900) already exists.\n",
      "\n",
      "duplicate key value violates unique constraint \"loans_pkey\"\n",
      "DETAIL:  Key (loan_id)=(6812) already exists.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fake_loans_commands = []\n",
    "\n",
    "for data in loan_data:\n",
    "    # date formatting requires to not use execute_commands\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(\"INSERT INTO loans(loan_id, copy_id, start_date, end_date, person_id) VALUES (%s, %s, %s, %s, %s)\", (data[0], data[1], data[2], data[3], data[4]))\n",
    "        cur.close()\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        conn.rollback()\n",
    "        cur.close()\n",
    "        cur = None\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df1ae5a0-e282-4994-966b-52812c44d21c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5871, 6366, 238)]\n"
     ]
    }
   ],
   "source": [
    "OWNER_ID = 238\n",
    "execute_commands(f\"SELECT * FROM copies WHERE person_id = {OWNER_ID};\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "eba716b8-ceb6-4703-a114-50991231eb54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(5871, 2), (913, 2), (6915, 2), (612, 2)]\n"
     ]
    }
   ],
   "source": [
    "execute_commands(\"SELECT copy_id, COUNT(*) FROM loans GROUP BY copy_id HAVING COUNT(*) > 1;\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "04ad9790-986c-4036-a594-168b665607f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4427, 2773, datetime.date(2022, 9, 10), datetime.date(2022, 11, 27), 9455), (1243, 913, datetime.date(2022, 10, 13), datetime.date(2023, 4, 25), 9455), (2049, 612, datetime.date(2022, 7, 4), datetime.date(2022, 11, 12), 9455), (2950, 612, datetime.date(2023, 1, 29), datetime.date(2023, 3, 9), 6800), (8615, 1371, datetime.date(2022, 6, 3), datetime.date(2022, 11, 10), 4636), (6549, 1080, datetime.date(2022, 12, 2), datetime.date(2023, 4, 16), 554), (6812, 5396, datetime.date(2022, 8, 13), datetime.date(2022, 12, 28), 9799)]\n"
     ]
    }
   ],
   "source": [
    "execute_commands(\"SELECT * FROM loans WHERE end_date - start_date > 7;\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dab1bca5-a6b8-43d8-b3ed-5cc17ccf2228",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1885, 'Contemporary R&B', 'James Woods'), (4852, 'Parody Music', 'Matthew Armstrong')]\n"
     ]
    }
   ],
   "source": [
    "execute_commands(\"SELECT * FROM albums WHERE album_id NOT IN (SELECT DISTINCT album_id FROM copies JOIN loans ON copies.copy_id = loans.copy_id);\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0ddb5-ebab-466a-aa65-2216bcbc83e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
